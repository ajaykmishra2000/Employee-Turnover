{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee Turnover Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: \n",
    "### The employee turnover "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The employee turnover problem is one of the most common problems at work. As per the Center of American progress, the cost of replacing an employee is 20% of that worker's yearly income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import your libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "__author__ = \"Ajay Mishra\"\n",
    "__email__ = \"ajaykmishra2000@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - DISCOVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Reading the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Employee Turnover/data/HR-data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'Employee Turnover/data/HR-data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a4ddb1f31536>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Employee Turnover/data/HR-data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'Employee Turnover/data/HR-data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Employee Turnover/data/HR-data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sales'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Data Cleaning ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing value in the dataset\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df = df.rename(columns = {'satisfaction_level':'satisfaction',\n",
    "                         'last_evaluation':'evaluation',\n",
    "                         'number_project':'projectCount',\n",
    "                         'average_montly_hours':'AvgMonthlyHours',\n",
    "                         'time_spend_company':'yearsAtCompany',\n",
    "                         'Work_accident':'accidentAtWork',\n",
    "                         'left':'turnover',\n",
    "                         'promotion_last_5years':'promotion',\n",
    "                         'sales':'department'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for duplicate data, invalid data (e.g. salaries <=0), or corrupt data and remove it\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop_duplicates().reset_index(drop=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- EDA ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize each feature variable\n",
    "#summarize the target variable\n",
    "#look for correlation between each feature and the target\n",
    "#look for correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['turnover'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate turnover rates\n",
    "turnover_rate = df.turnover.value_counts()/df.shape[0]\n",
    "turnover_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical overview of dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunover_Summary=df.groupby('turnover')\n",
    "trunover_Summary.agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunover_Summary.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Correlation Matrix ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "sns.heatmap(corr,\n",
    "           xticklabels=corr.columns.values,\n",
    "           yticklabels=corr.columns.values,\n",
    "           cmap='BuPu',\n",
    "           linewidth=2)\n",
    "plt.title('Heatmap employee turnover')\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Distribution of features ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "# satisfaction distribution\n",
    "ax1 = fig.add_subplot(241)\n",
    "df.hist(column='satisfaction',ax=ax1, color='limegreen')\n",
    "ax1.set_xlabel('satisfaction')\n",
    "ax1.set_title('satisfaction distribution')\n",
    "\n",
    "# evaluation distribution\n",
    "ax2 = fig.add_subplot(242)\n",
    "df.hist(column='evaluation',ax=ax2, color='royalblue')\n",
    "ax2.set_xlabel('evaluation')\n",
    "ax2.set_title('evaluation distribution')\n",
    "\n",
    "# projectCount distribution\n",
    "ax3 = fig.add_subplot(243)\n",
    "df.hist(column='projectCount',ax=ax3, color='turquoise')\n",
    "ax3.set_xlabel('projectCount')\n",
    "ax3.set_title('projectCount distribution')\n",
    "\n",
    "# AvgMonthlyHours distribution\n",
    "ax4 = fig.add_subplot(244)\n",
    "df.hist(column='AvgMonthlyHours',ax=ax4, color='slateblue')\n",
    "ax4.set_xlabel('AvgMonthlyHours')\n",
    "ax4.set_title('AvgMonthlyHours distribution')\n",
    "\n",
    "# yearsAtCompany distribution\n",
    "ax5 = fig.add_subplot(245)\n",
    "df.hist(column='yearsAtCompany',ax=ax5, color='lightcoral')\n",
    "ax5.set_xlabel('yearsAtCompany')\n",
    "ax5.set_title('yearsAtCompany distribution')\n",
    "\n",
    "# accidentAtWork distribution\n",
    "ax6 = fig.add_subplot(246)\n",
    "df.hist(column='accidentAtWork',ax=ax6, color='teal')\n",
    "ax6.set_xlabel('accidentAtWork')\n",
    "ax6.set_title('accidentAtWork distribution')\n",
    "\n",
    "# turnover distribution\n",
    "ax7 = fig.add_subplot(247)\n",
    "df.hist(column='turnover',ax=ax7, color='plum')\n",
    "ax7.set_xlabel('turnover')\n",
    "ax7.set_title('turnover distribution')\n",
    "\n",
    "# promotion distribution\n",
    "ax8 = fig.add_subplot(248)\n",
    "df.hist(column='promotion',ax=ax8, color='olive')\n",
    "ax8.set_xlabel('promotion')\n",
    "ax8.set_title('promotion distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='satisfaction',y='evaluation',data=df,\n",
    "          fit_reg=False,\n",
    "          hue='turnover')\n",
    "plt.title('satisfaction Vs evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='evaluation',y='AvgMonthlyHours',data=df,\n",
    "          fit_reg=False,\n",
    "          hue='turnover')\n",
    "plt.title('evaluation Vs AvgMonthlyHours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='satisfaction',y='AvgMonthlyHours',data=df,\n",
    "          fit_reg=False,\n",
    "          hue='turnover')\n",
    "plt.title('satisfaction Vs AvgMonthlyHours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Clustering employee turnover ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3,random_state=2)\n",
    "kmeans.fit(df[df.turnover==1][['satisfaction','evaluation']])\n",
    "kmeans.labels_\n",
    "#kmeans.inertia_\n",
    "#kmeans.n_iter_\n",
    "#kmeans.cluster_centers_ \n",
    "kmeans_color = ['green' if c == 0 else 'blue' if c == 2 else 'red' for c in kmeans.labels_]\n",
    "\n",
    "fig = plt.figure(figsize=(11,6))\n",
    "plt.scatter(x='satisfaction',y='evaluation', data=df[df['turnover']==1],\n",
    "           alpha=0.25, color=kmeans_color)\n",
    "plt.xlabel('Satisfaction')\n",
    "plt.ylabel('Evaluation')\n",
    "plt.scatter(x=kmeans.cluster_centers_[:,0],y=kmeans.cluster_centers_[:,1],marker='X',color='black',s=100)\n",
    "plt.title('Cluster of employee turnover')\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,4))\n",
    "ax=sns.kdeplot(df[df['turnover']==0]['satisfaction'],color='b', shade=True, label='no turnover')\n",
    "ax=sns.kdeplot(df[df['turnover']==1]['satisfaction'],color='r', shade=True, label='turnover')\n",
    "plt.title('Employee Satisfaction Distribution: Turnover Vs No Turnover')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Project Count ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,4))\n",
    "sns.barplot(x='projectCount',y='projectCount', hue='turnover',data=df, estimator=lambda x: len(x) / len(df) * 100)\n",
    "ax.set(xlabel='# of Projects', ylabel = 'Counts',\n",
    "      title='Project Count Distribution: Turnover Vs No Turnover')\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Turnover by Department   ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['turnover']==1]['department'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_left = df[df['turnover']==1]\n",
    "emp_left = pd.DataFrame(emp_left.department.value_counts()).reset_index()\n",
    "emp_left\n",
    "emp_total = pd.DataFrame(df.department.value_counts()).reset_index()\n",
    "emp_total\n",
    "\n",
    "employee_df = pd.merge(emp_total,emp_left,how='inner',on='index')\n",
    "employee_df = employee_df.rename(columns = {'index':'department','department_x':'EmployeeTotal','department_y':'EmployeeLeft'})\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = \"whitegrid\")\n",
    "f, ax = plt.subplots(figsize=(12,5))\n",
    "\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x='EmployeeTotal',y='department',data=employee_df,\n",
    "            label='Total', color='lightskyblue')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='EmployeeLeft',y='department',data=employee_df,\n",
    "            label='left',color='r')\n",
    "\n",
    "ax.legend(ncol=2, loc=\"lower right\",frameon=True)\n",
    "ax.set(xlabel='Total Employees',ylabel='Departments',\n",
    "      title='Employees per Department')\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Average Monthly Hours ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15,4))\n",
    "ax = sns.kdeplot(df[df['turnover']==0]['AvgMonthlyHours'],color='b',shade=True, label='no turnover')\n",
    "ax = sns.kdeplot(df[df['turnover']==1]['AvgMonthlyHours'],color='r',shade=True, label='turnover')\n",
    "\n",
    "ax.set(xlabel='Average Monthly Hours', ylabel='Frequency',\n",
    "      title='Average Monthly Hours Distribution: Turnover Vs No Turnover')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Preprocessing ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = ['turnover','department','salary','promotion']\n",
    "num_var = ['satisfaction','evaluation','projectCount','AvgMonthlyHours','yearsAtCompany','accidentAtWork']\n",
    "df_cat = pd.get_dummies(df[cat_var],drop_first=True)\n",
    "df_num = df[num_var]\n",
    "new_df = pd.concat([df_cat,df_num], axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Class Balance ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_rate = new_df['turnover'].value_counts()/new_df.shape[0]\n",
    "turnover_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turnover_rate.values\n",
    "#turnover_rate.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(9,5))\n",
    "sns.barplot(x=turnover_rate.index,y=turnover_rate.values,data=new_df)\n",
    "ax.set(xlabel='Employee Turnover',ylabel='Count',\n",
    "      title='Employee Turnover Distribution')\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Split dataset: Training / Test ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report,precision_score, recall_score, confusion_matrix, precision_recall_curve \n",
    "\n",
    "X = new_df.iloc[:,1:]\n",
    "y = new_df.iloc[:,0]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=123,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Resample data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsample Minority class\n",
    "X_train_up, y_train_up = resample(X_train[y_train == 1],\n",
    "                                y_train[y_train == 1],\n",
    "                                replace=True,\n",
    "                                n_samples=X_train[y_train == 0].shape[0],\n",
    "                                random_state=1)\n",
    "\n",
    "X_train_up = np.concatenate((X_train[y_train==0],X_train_up))\n",
    "y_train_up = np.concatenate((y_train[y_train==0],y_train_up))\n",
    "\n",
    "# Upscale using SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio=1.0)\n",
    "X_train_sm,y_train_sm = sm.fit_sample(X_train,y_train)\n",
    "\n",
    "#downsample Majority class\n",
    "X_train_dn, y_train_dn = resample(X_train[y_train == 0],\n",
    "                                y_train[y_train == 0],\n",
    "                                replace=True,\n",
    "                                n_samples=X_train[y_train == 1].shape[0],\n",
    "                                random_state=1)\n",
    "\n",
    "X_train_dn = np.concatenate((X_train[y_train==1],X_train_dn))\n",
    "y_train_dn = np.concatenate((y_train[y_train==1],y_train_dn))\n",
    "\n",
    "\n",
    "print('Original Shape ====>',X_train.shape,y_train.shape)\n",
    "\n",
    "print('Upsample Shape ====>',X_train_up.shape,y_train_up.shape)\n",
    "\n",
    "print('SMOTE Shape    ====>',X_train_sm.shape,y_train_sm.shape)\n",
    "\n",
    "print('Downsample Shape ==>',X_train_dn.shape,y_train_dn.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Chossing best Sampling technique ----    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Best sampling method is SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Trained logistic regression on all sampled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "resample_methods = {'Original':(X_train,y_train),\n",
    "                   'Upsampled':(X_train_up,y_train_up),\n",
    "                   'SMOTE':(X_train_sm,y_train_sm),\n",
    "                   'Downsampled':(X_train_dn,y_train_dn)}\n",
    "\n",
    "for method in resample_methods.keys():\n",
    "    #print(method)\n",
    "    lr_results = cross_val_score(LogisticRegression(solver='liblinear'),resample_methods[method][0],resample_methods[method][1],cv=5,scoring='f1')\n",
    "    print('The best F1 score {method} data',method,'method' ,'=====>',lr_results.mean())\n",
    "    \n",
    "cross_val_score(LogisticRegression(class_weight='balanced'),X_train,y_train,cv=5,scoring='f1').mean()\n",
    "#cross_val_score(LogisticRegression(class_weight='balanced'), X_train, y_train, cv=5, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Train models ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Gradient Boosting Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression f1 score: 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X_train_sm,y_train_sm)\n",
    "\n",
    "lr.predict(X_test)\n",
    "lr_auc = roc_auc_score(y_test,lr.predict(X_test))\n",
    "\n",
    "print('Logistic regression AUC = %2.2f' % lr_auc)\n",
    "\n",
    "print(classification_report(y_test,lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5 fold cross validation on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_result = cross_val_score(rf,X_train_sm,y_train_sm,cv=5,scoring='f1')\n",
    "rf_result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest F1 score: 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rf = rf.fit(X_train_sm,y_train_sm)\n",
    "\n",
    "rf_auc = roc_auc_score(y_test,rf.predict(X_test))\n",
    "\n",
    "print('Random Forest AUC is %2.2f'% rf_auc)\n",
    "\n",
    "print(classification_report(y_test,rf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting CLassifier f1 score: 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "gbc =gbc.fit(X_train,y_train)\n",
    "\n",
    "gbc_auc = roc_auc_score(y_test,gbc.predict(X_test))\n",
    "print('Gradient Boosing Classifier AUC Score is %2.2f' % gbc_auc)\n",
    "\n",
    "print(classification_report(y_test,gbc.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "lr_fpr,lr_tpr, lr_thresholds = roc_curve(y_test,lr.predict_proba(X_test)[:,1])\n",
    "\n",
    "rf_fpr,rf_tpr, rf_thresholds = roc_curve(y_test,rf.predict_proba(X_test)[:,1])\n",
    "\n",
    "gbc_fpr,gbc_tpr, gbc_thresholds = roc_curve(y_test,gbc.predict_proba(X_test)[:,1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "# Logistic Regression AUC\n",
    "plt.plot(lr_fpr,lr_tpr, label = 'Logistic Regression (area = %2.2f)' %lr_auc)\n",
    "# Random Forest AUC\n",
    "plt.plot(rf_fpr,rf_tpr, label = 'Random Forest (area = %2.2f)' %rf_auc)\n",
    "# Gradient Boosting Classification AUC\n",
    "plt.plot(gbc_fpr,gbc_tpr, label = 'Gradient Boosting Classification (area = %2.2f)' %gbc_auc)\n",
    "# Base AUC\n",
    "plt.plot([0,1],[0,1], label = 'Base Area')\n",
    "\n",
    "ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate', title='ROC graph')\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix - Logistic regression\n",
    "confusion_matrix(y_test,lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix - Random Forest\n",
    "confusion_matrix(y_test,rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix - Gradient Boosting Classification\n",
    "confusion_matrix(y_test,gbc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Random Forest feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(rf.feature_importances_,\n",
    "            index=X_test.columns,\n",
    "            columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importance = feature_importance.reset_index() \n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6)) \n",
    "sns.barplot(x='importance',y='index',data=feature_importance)\n",
    "ax.set(xlabel='Importance',ylabel='Features', title='Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- Apply random Noise ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.normal(0,1,10)\n",
    "X_train_noise = pd.DataFrame(X_train)\n",
    "X_train_noise['randomNoise']=np.random.normal(0,1,X_train_noise.shape[0])\n",
    "\n",
    "rf_random = RandomForestClassifier()\n",
    "rf_normal =rf_random.fit(X_train_noise,y_train)\n",
    "\n",
    "feature_importance_noise = pd.DataFrame(rf_random.feature_importances_,index=X_train_noise.columns,\n",
    "                                                 columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importance_noise = feature_importance_noise.reset_index() \n",
    "feature_importance_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6)) \n",
    "clrs =['red' if (x==5) else 'green' for x in feature_importance_noise.index.values]\n",
    "sns.barplot(x='importance',y='index',data=feature_importance_noise, palette=clrs)\n",
    "ax.set(xlabel='Importance',ylabel='Features', title='Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Save Best Model ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(rf,'Employee Turnover/EmployeeTurnoverModel-v1.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
